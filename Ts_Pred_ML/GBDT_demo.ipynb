{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 调参：\n",
    "<br>loss：损失函数。有deviance和exponential两种。deviance是采用对数似然，exponential是指数损失，后者相当于AdaBoost。\n",
    "<br>n_estimators:最大弱学习器个数，默认是100，调参时要注意过拟合或欠拟合，一般和learning_rate一起考虑。\n",
    "<br>learning_rate:步长，即每个弱学习器的权重缩减系数，默认为0.1，取值范围0-1，当取值为1时，相当于权重不缩减。较小的learning_rate相当于更多的迭代次数。\n",
    "<br>subsample:子采样，默认为1，取值范围(0,1]，当取值为1时，相当于没有采样。小于1时，即进行采样，按比例采样得到的样本去构建弱学习器。这样做可以防止过拟合，但是值不能太低，会造成高方差。\n",
    "<br>init：初始化弱学习器。不使用的话就是第一轮迭代构建的弱学习器.如果没有先验的话就可以不用管\n",
    "\n",
    "\n",
    "由于GBDT使用CART回归决策树。以下参数用于调优弱学习器，主要都是为了防止过拟合\n",
    "<br>max_feature：树分裂时考虑的最大特征数，默认为None，也就是考虑所有特征。可以取值有：log2,auto,sqrt\n",
    "<br>max_depth：CART最大深度，默认为None\n",
    "<br>min_sample_split：划分节点时需要保留的样本数。当某节点的样本数小于某个值时，就当做叶子节点，不允许再分裂。默认是2\n",
    "<br>min_sample_leaf：叶子节点最少样本数。如果某个叶子节点数量少于某个值，会同它的兄弟节点一起被剪枝。默认是1\n",
    "<br>min_weight_fraction_leaf：叶子节点最小的样本权重和。如果小于某个值，会同它的兄弟节点一起被剪枝。一般用于权重变化的样本。默认是0\n",
    "<br>min_leaf_nodes：最大叶子节点数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3) (4,) (1, 3) (1, 1)\n",
      "1 [1]\n",
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "# 二分类\n",
    "gbdt = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=5, subsample=1\n",
    "                                  , min_samples_split=2, min_samples_leaf=1, max_depth=3\n",
    "                                  , init=None, random_state=None, max_features=None\n",
    "                                  , verbose=0, max_leaf_nodes=None, warm_start=False)\n",
    "\n",
    "train_feat = np.array([[1, 5, 20],\n",
    "                       [2, 7, 30],\n",
    "                       [3, 21, 70],\n",
    "                       [4, 30, 60],])\n",
    "train_label = np.array([[0], [0], [1], [1]]).ravel()\n",
    "\n",
    "test_feat = np.array([[5, 25, 65]])\n",
    "test_label = np.array([[1]])\n",
    "print(train_feat.shape, train_label.shape, test_feat.shape, test_label.shape)\n",
    "\n",
    "gbdt.fit(train_feat, train_label)\n",
    "pred = gbdt.predict(test_feat)\n",
    "\n",
    "total_err = 0\n",
    "for i in range(pred.shape[0]):\n",
    "    print(pred[i], test_label[i])\n",
    "    err = (pred[i] - test_label[i]) / test_label[i]\n",
    "    total_err += err * err\n",
    "print(total_err / pred.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1",
   "language": "python",
   "name": "tf1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
